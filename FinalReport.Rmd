---
title: "Final Project"
author: "Eric Peterson"
date: "`r Sys.Date()`"
output: html_document
---

## Aims

I am curious about what families decide to send their children to public school in Philadelphia. One way to measure what families are choosing public schools is to compare the number of births in a school catchment five years ago to the kindergarten enrollment this year. I can measure the qualities of the school catchments and attempt to make generalizations families with those qualities.

I initially indented to identify demographic qualities of school catchments associated with higher rates of converting live birth statistics five years ago to current kindergarten enrollments.
As my analysis progressed, I broadened my scope to assess qualities of the schools themselves and qualities of the location of the school.


## Background

School districts face uncertainty planning for their kindergarten enrollment. In the School District of Philadelphia (SDP) and other school systems starved of resources, individual schools can find themselves intent on maintaining enrollment to retain resources allocated based on enrollment. A rigorous, data-driven approach to predicting kindergarten enrollment could help with planning in the short term.

Identifying the trends among all schools can be helpful for raising enrollment in the district as a whole. First, by identifying catchments where fewer births translate to kindergarten enrollments, stakeholders can target resources for reversing that trend. Second, analyzing outliers could target attention on areas where policy is succeeding.


## Hypotheses

I expect there to be a positive correlation between births five years ago and current kindergarten enrollment.
$$H_0: R_{births, enrollment}^2 = 0 $$

$$H_A: R_{births, enrollment}^2 \neq 0 $$


I expect to see catchments where there are more white families in catchments to have lower participation in public schools.

$$H_0: R_{ratio, white}^2 = 0 $$

$$H_A: R_{ratio, white}^2 \neq 0 $$

<!-- TODO Catchments with greater variance in household income will have worse conversion. -->

## Variables of interest

### Births

Data for births by census tract is available through [internet archives](https://web.archive.org/web/20181107034101/https://www.phila.gov/health/Commissioner/VitalStatistics.html).
I assume births are evenly distributed throughout each tract. I'll assign births to catchments as a function of how much of each tract overlaps with each catchment.

### Enrollment

I'll use the available SDP enrollment data to find the number of students from each catchment enrolled in SDP kindergarten.

I assume that all of the kindergartners enrolled are in catchment. This is a notable limitation in the publicly available data. SDP provides home catchment crosstabs by school and demographic crosstabs by grade, but it does not provide catchment crosstabs by grade.

### Ratio

More precisely, this would be the ratio of enrollment at neighborhood school to live births in catchment. While there are other ratios of interest, I'll refer to this one the most. I'll call it enrollment ratio or births to enrollment ratio.
I'll use that enrollment to compute the conversion rate.

I've decided to use a five-year offset between births and enrollment because that algorithm produces a 75% overlap. A child is eligible for kindergarten at 5 years old in September. Births data is, presumably, calculated by calendar year starting in January.

|Month|Births Year|Kindergarten Year|
|-|-|
|01|2011|2016|
|02|2011|2016|
|03|2011|2016|
|04|2011|2016|
|05|2011|2016|
|06|2011|2016|
|07|2011|2016|
|08|2011|2016|
|09|2011|2017|
|10|2011|2017|
|11|2011|2017|
|12|2011|2017|

I assume that births are distributed over months equally.

This assumption can produce a great deal of variation. Births might change significantly year to year because of random variability month to month. We could be counting a significant number of births in November 2011 as kindergarten year 2016 that will show up as enrollments in kindergarten year 2017.

I assume that "redshirting" is uniform over years.

Families have latitude in when they decide to send children to school. A child born in August 2011 could go to school when they are 6 instead of 5. Commentators have started using ["redshirt"](https://www.parentdata.org/p/back-to-school-q-and-a-redshirting) to describe this practice. I think it's reasonable to assume that the redshirts from 2016 to 2017 will take the seats of the redshirts from 2017 to 2018.


### Catchments

A catchment is a geographic associated with a neighborhood school. Families can request to enroll a child at a school outside their catchment.

Elementary school catchments are the most granular element of the district feeder pattern. All students in-catchment for an elementary school will be in-catchment for the same middle school. All students in-catchment for a middle school will be in-catchment for the same high-school.

Catchments do not line up particularly well with census tracts. The Census and ACS do not provide statistics about SDP catchment geographies, unfortunately.


### Census tracts

Census tracts change once a census, or once a decade. I'm fortunate that my data all falls into years when the 2010 census were current. Future work will need to incorperate 2020 census shapes.


### Census data

The Census Bureau publishes 5-year estimates of the American Community Survey. I'll rely on these ACS 5-year estimates for a few reasons:

- The 5-year estimates are available over a long period of time. Because ACS methodology is consistent over time, this allows our analysis to scale over more years if/as more years of births data become available. In years of the decennial census, we could use census data. We could even compute some census information with the granularity of block groups, which might be more accurate than calculating the intersection of relatively large tract shapes. It's reasonable to suggest that demographics don't changes particularly quickly (I plan to show that overall they don't), but I'd like to leave the possibility of analyzing changes year to year open to the future researcher.
- The 5-year interval is handy for computing changes between birth and enrollment, which is coincidentally also 5 years. We can see if changes to catchments over that 5-year period affect the ratio.
- The Census API isn't returning block group data for the 2010 census. I am prioritizing the reproducability of the database _and_ the analysis, so one-click building of the data set is important to me. If I was going to be limited to 2010 tract-level data, I'm willing to sacrifice the exactness of the census for the possibility of computing methodologically sound changes over 5 year periods.


### School Performance

SDP publishes results of their standardized testing (with crosstabs). While I ingest all of the available standardized testing data, my analysis focuses on the third grade English and language arts (ELA) PSSA score. I use the district-reported percentage of students scoring 3 or 4, grades considered "passing" as a proxy for academic quality of kindergarten.

### Location of schools

SDP publishes the gps coordinates of schools, starting in 2017. I've used school location data to analyze the location of charter schools in relation to district schools.


## Pipeline

The script `load_data.py` will download, parse, and load to a PostGIS database all of the raw data. Because the births data required manual intervention to parse, and because of the tenuousness of relying on an internet archive, I've cleaned the births data and provided it as part of the project repository.

The file `transforms.sql` creates a series of tables in PostGIS that organizes the raw data into more useful relationships. This analysis will consume the resulting `public.comparison` table.

I aspire to cutting a version of this project at the time of submission. If this markdown isn't compiling because of issues with database structure, it might be because I'm working on it. Switch the branch to a tagged version (probably `v0.0.1`) and see if that helps!

A summary so far:

1. python script

* Download births files from internet archive -> 
            Manually clean files ->
                       Load each file to a table in PostGIS

* Download enrollment data from SDP DPO ->
            Parse out the data from the files (in three formats) ->
                       Load each file to a table in PostGIS

* Load 2010 census tract shape files
  - ogr2ogr subprocess call

* Load 2010 census block group shape files
  - ogr2ogr subprocess call

* Load 2010 census data: race, TODO others
  - api call

* Download catchment shape files from SDP DPO ->
            Unzip each file ->
                      ogr2ogr subprocess call to load just the elementary school catchments

2. sql script
  
  * Union all catchment years together
  
  * Find intersections of catchments and census tracts. Compute the ratio of each tract in each catchment.
  
  * Find intersections of catchments and census block groups. Compute the ratio of each block group in each catchment.

  * Union all birth years together
  
  * Compute births by catchment
    - Join births to the intersection of tracts and catchments.
    - Multiply the births in catchment by the ratio of area in each tract.
    - Sum the area-weighted births by catchment as our count of births by catchment.

  * Union all enrollment years together
  
  * Join enrollments to the count of births by catchment. Compute the ratio of births to enrollments.
  
  * Compute demographic information about catchments
    - Join demographics to the intersection of block groups and catchments.
    - Multiply the raw counts of each demographic by the ratio of area in each block group.
    - Sum the area-weighted raw counts by catchment.
    - Compute the proportion of each demographic for each catchment.

## Analysis in R

### Exploration

The below scatterplots display summary plots of the various variables of interest.

```{r, echo=F, "Connection"}
library(RPostgreSQL)
library(ggplot2)
library(tidyr)
library(dplyr)
library(explore)
library(dotwhisker)

dsn_database <- 'sdp'
dsn_hostname <- 'localhost'
dsn_port <- 5432
dsn_uid <- '' # TODO specify the username locally. Don't commit code with credentials
#dsn_pwd <- ''

tryCatch({
    drv <- dbDriver("PostgreSQL")
    print("Connecting to Database…")
    connec <- dbConnect(drv, 
                 dbname = dsn_database,
                 host = dsn_hostname, 
                 port = dsn_port,
                 user = dsn_uid
                 )
    on.exit(dbDisconnect(connec))
    print("Database Connected!")
    },
    error=function(cond) {
            print("Unable to connect to Database.")
    })
```


```{r, echo=F, "Comparison"}

full_compare_query <- "select * from public.comparison"

df_full_compare <- dbGetQuery(connec, full_compare_query)

df_full_compare$catchment_year <- as.factor(df_full_compare$catchment_year)
#head(df_full_compare[2:8])

#explore_all(df_full_compare, target = ratio)
#explore_all(df_full_compare, target = ratio_delta)
#explore(df_full_compare)

#names(df_full_compare)
df_full_compare$median_household_income[df_full_compare$median_household_income < -20000] <- NA
df_full_compare$income_delta[df_full_compare$income_delta > 40000] <- NA
pairs(df_full_compare[c(3,9, 4:8, 12, 18)])

```



### Births and Enrollments

Births and enrollment are correlated.

There is noticeable hetroscedasticity between births and enrollment.


```{r, "Births_Enrollments"}

ggplot(df_full_compare, aes(x=total_births, y=total_enrolled)) +
  geom_point()

# TODO confirm the significance of this correlation, explore the strength

model.ratio <- lm(total_enrolled ~ total_births, data=df_full_compare)
model.ratio.a <- lm(log(total_enrolled) ~ log(total_births), data=df_full_compare)
#model.ratio.b <- lm(    total_enrolled  ~ log(total_births), data=df_full_compare)
model.ratio.c <- lm(log(total_enrolled) ~     total_births , data=df_full_compare)


intercept.ratio <- coefficients(model.ratio)[1]
slope.ratio <- coefficients(model.ratio)[2]

ggplot(df_full_compare, aes(x=total_births, y=total_enrolled)) +
  geom_point() +
  geom_abline(intercept = intercept.ratio,
              slope = slope.ratio)

intercept.ratio.a <- coefficients(model.ratio.a)[1]
slope.ratio.a <- coefficients(model.ratio.a)[2]

ggplot(df_full_compare, aes(x=log(total_births), y=log(total_enrolled))) +
  geom_point() +
  geom_abline(intercept = intercept.ratio.a,
              slope = slope.ratio.a)

intercept.ratio.c <- coefficients(model.ratio.c)[1]
slope.ratio.c <- coefficients(model.ratio.c)[2]

ggplot(df_full_compare, aes(x=total_births, y=log(total_enrolled))) +
  geom_point() +
  geom_abline(intercept = intercept.ratio.c,
              slope = slope.ratio.c)


#summary(model.ratio.c)
plot(model.ratio)
plot(model.ratio.a)
#plot(model.ratio.b)
plot(model.ratio.c) # c looks like the better fit
# TODO put a log around this variable, re-draw plots?

```


Unfortunately, we don't see a particularly strong correlation between the changes in births and the changes in enrollment.

```{r, "Births_Enrollments_Deltas"}

ggplot(df_full_compare, aes(x=births_delta, y=enrolled_delta)) +
  geom_point()

```



### Income variability

Because the ACS only gives us median household income, we don't have a robust way to measure the shape of the distribution of income inside a catchment. I've considered two proxies for measuring the variation of income:

1. Use the published margin of error of median household income as a proxy for variability

  - This approach has several downsides. First, the margin of error tracks extraordinarily well with income - we'd probably end up just re-discovering the correlation with raw income.
  - Second, it might not be statistically valid. 

2. Compute the difference between the highest and lowest median household income in the catchment.

  - This has the advantage of controlling for the phenomenon of higher income having higher ratio again

This is slightly more tricky to do because it's all in sql.

```{r, "Income_Margin"}

income_margin_query <- "select * from census.acs_tract_2015"

df.income.margin <- dbGetQuery(connec, income_margin_query)

df.income.margin$median_household_income <- as.numeric(df.income.margin$median_household_income)
df.income.margin$median_household_income_margin <- as.numeric(df.income.margin$median_household_income_margin)
df.income.margin$median_household_income_margin[df.income.margin$median_household_income_margin < -.00001] <- NA
df.income.margin$median_household_income_margin[df.income.margin$median_household_income_margin > 30000] <- NA
df.income.margin <- subset(df.income.margin, complete.cases((df.income.margin)))

#head(df.income.margin)

boxplot(df.income.margin$median_household_income_margin)

boxplot(df.income.margin$median_household_income_margin / df.income.margin$median_household_income)

ggplot(df.income.margin, aes(x=median_household_income, y=median_household_income_margin)) +
  geom_point()

hist(df.income.margin$median_household_income_margin / df.income.margin$median_household_income)

```


```{r, "Explore_Likely_correlations"}

ggplot(df_full_compare, aes(x=catchment_year, y=ratio, group=catchment_year, color=catchment_year)) +
  coord_flip() +
  geom_boxplot()

# remove outliers that ruin our income data
df.income <- df_full_compare[c(1,2,3,7,8, 18)]
df.income$median_household_income[df.income$median_household_income < -20000] <- NA
df.income <- subset(df.income, complete.cases(df.income))

ggplot(df.income, aes(x=median_household_income, y=ratio)) +
  geom_point()


ggplot(df.income, aes(x=log(median_household_income), y=ratio)) +
  geom_point()

# you'd expect raw income delta over time to track nearly perfectly with the median income, which it does.
#ggplot(df.income, aes(x=income_delta, y=ratio)) +
#  geom_point()


ggplot(df.income, aes(x=median_household_income_diff, y=ratio)) +
  geom_point()

# TODO Compare the relative strengths of the two models

```

### Takeaways

- There's skew in the distribution of ratios
- There's no apparent correlation between race and ratio
- There might be slight correlation in the relationship between income and ratio.
- There seems to be clustering around zero change in ratio deltas and income deltas.


Being in a catchment next to a charter school catchment doesn't affect your ratio too much.

```{r, "charter_explore"}

df.charter <- df_full_compare[c(1, 3, 13, 14, 17)]

# remove years that don't have coordinate information
df.charter$catchment_year[as.numeric(as.character(df.charter$catchment_year)) <= 2016] <- NA
df.charter <- subset(df.charter, complete.cases(df.charter))

df.charter$contains_charter <- as.factor(df.charter$contains_charter)

ggplot(df.charter, aes(x=contains_charter, y=ratio, fill=catchment_year)) +
  coord_flip() +
  geom_boxplot()

# ANOVA for full population
anova.charter <- aov(ratio ~ contains_charter, data=df.charter)
summary(anova.charter)
tuk.charter <- TukeyHSD(anova.charter)
tuk.charter

# repeat the analysis for each year
# 2017
df.charter.2017 <- subset(df.charter, as.character(df.charter$catchment_year) == "2017")
anova.charter.2017 <- aov(ratio ~ contains_charter, data=df.charter.2017)
summary(anova.charter.2017)

# 2018
df.charter.2018 <- subset(df.charter, as.character(df.charter$catchment_year) == "2018")
anova.charter.2018 <- aov(ratio ~ contains_charter, data=df.charter.2018)
summary(anova.charter.2018)

# 2019
df.charter.2019 <- subset(df.charter, as.character(df.charter$catchment_year) == "2019")
anova.charter.2019 <- aov(ratio ~ contains_charter, data=df.charter.2019)
summary(anova.charter.2019)


ggplot(df.charter, aes(x=total_births, y=total_enrolled, color=contains_charter)) +
  geom_point()

```

Catchments with charter schools in them have a different distribution than catchments without charter schools.
The distinction between charters and non-charters becomes more pronounced between 2017 and 2019

- Does the distance of a charter school from the neighborhood school affect this ratio?



```{r, "2016_ela_scores_explore"}

ggplot(df_full_compare, aes(x=pass_percent, y=ratio)) +
  geom_point()


```


```{r, echo=F, "Distribution_of_race"}

race_query <- 'select census_year as "year", es_short as school, pct_white, pct_black from public.demog_by_catchment where catchment_year = 2019'
df <- dbGetQuery(connec, race_query)
df$year <- as.factor(df$year)

# plot changes to demographics over time
df_plot <- pivot_longer(df, c(pct_white, pct_black))
df_plot$year <- as.factor(df_plot$year)

# there's very little change in the distribution of schools over time
ggplot(df_plot, aes(x=name, y=value, color=year)) +
  coord_flip() +
  geom_boxplot()
```


The length of stay of a principal doesn't seem to have a direct effect on the data. There's not enough evidence to assume that the coefficient of correlation isn't zero.

```{r, "Distribution_of_tenure"}


ggplot(df_full_compare, aes(x=cumulative_tenure, y=ratio)) +
  geom_point()

model.tenure <- lm(ratio ~ cumulative_tenure, data = df_full_compare)


summary(model.tenure)

```


```{r, "Distribution_of_tenure"}

df.distance <- df_full_compare[c(1, 2, 3, 21)]
df.distance <- subset(df.distance, complete.cases(df.distance))

ggplot(df.distance, aes(x=charter_distance, y=ratio)) +
  geom_point()

model.distance <- lm(ratio ~ charter_distance, data = df.distance)


summary(model.distance)
plot(model.distance)



ggplot(df.distance, aes(x=log(charter_distance), y=ratio)) +
  geom_point()

model.distance.a <- lm(ratio ~ log(charter_distance), data = df.distance)

summary(model.distance.a)
plot(model.distance.a)



# this is actually a decent correlation. Don't throw this one away.
ggplot(df.distance, aes(x=charter_distance, y=log(ratio))) +
  geom_point()

model.distance.b <- lm(log(ratio) ~ charter_distance, data = df.distance)

summary(model.distance.b)
plot(model.distance.b)

```

There's very little change in the distribution of schools over time



```{r, "Multivariate_1"}

model.1 <- lm(total_enrolled ~ total_births + median_household_income_diff, data=df_full_compare)

summary(model.1)


model.2 <- lm(log(total_enrolled) ~ total_births + median_household_income_diff, data=df_full_compare)

summary(model.2)


model.3 <- lm(log(total_enrolled) ~ total_births + median_household_income, data=df_full_compare)

summary(model.3)


model.4 <- lm(log(total_enrolled) ~ total_births + median_household_income + contains_charter, data=df_full_compare)

summary(model.4)


plot(model.4)


anova(model.3, model.4)



model.5 <- lm(log(total_enrolled) ~ total_births + contains_charter, data=df_full_compare)

summary(model.5)

plot(model.5)

anova(model.4, model.5)


# assume no schools have moved, which I should double check
model.6 <- lm(log(total_enrolled) ~ total_births + median_household_income + charter_distance, data=df_full_compare)
plot(model.6)
summary(model.6)

# charter distance and charter contains tell us the same thing.
# distance is stronger
# but residuals on contains are much cleaner
#anova(model.4, model.6)



model.7 <- lm(log(total_enrolled) ~ total_births + median_household_income_diff + charter_distance + pct_white, data=df_full_compare)

summary(model.7)

model.7.1 <- lm(log(total_enrolled) ~ total_births + median_household_income + charter_distance + pct_white, data=df_full_compare)

summary(model.7.1)

# income and diff tell us the same thing. Income works slightly better
anova(model.7, model.7.1)

model.7.2 <- lm(log(total_enrolled) ~ total_births + median_household_income + contains_charter + pct_white, data=df_full_compare)

summary(model.7.2)

# looks like residuals are better with contains charter
plot(model.7.2)

# in terms of power distance and contains are the same
anova(model.7.1, model.7.2)


model.7.3 <- lm(log(total_enrolled) ~ total_births + median_household_income_diff + contains_charter + pct_white, data=df_full_compare)

summary(model.7.3)
# using diff ruins my residuals
plot(model.7.3)


model.8 <- lm(log(total_enrolled) ~ total_births +
                median_household_income + 
                charter_distance + pct_white + 
                population_density
              , data=df_full_compare)
# bad residuals
summary(model.8)

# pass percent has lots of missing rows.
# We only have 2016 data, so it's mutually exclusive with charter_distance
model.9 <- lm(log(total_enrolled) ~ total_births +
                median_household_income + 
                charter_distance + 
                pct_white + 
                cumulative_tenure
              , data=df_full_compare)
# bad residuals
summary(model.9)

#df_full_compare$median_household_income_diff[df_full_compare$median_household_income_diff > 0] <- NA

#df_full_compare <- subset(df_full_compare, complete.cases(df_full_compare))
model.10 <- lm(log(total_enrolled) ~ total_births +
                median_household_income + 
                contains_charter +
                pct_white
              , data=df_full_compare)
# bad residuals
summary(model.10)


model.7.2.1 <- lm(log(total_enrolled) ~ total_births +
                    median_household_income + 
                    contains_charter + 
                    pct_white + 
                    pass_percent
                  , data=df_full_compare)

# at higher fitted values, the model doesn't fit as well
summary(model.7.2.1)
plot(model.7.2.1)


model.7.2.2 <- lm(log(total_enrolled) ~ total_births +
                    median_household_income + 
                    contains_charter + 
                    pct_black + 
                    pass_percent # pass percent becomes unexplanatory when I add all years
                  , data=df_full_compare)
# still has some hetrosecasdasticity
summary(model.7.2.2)
plot(model.7.2.2)
vif(model.7.2.2)

model.7.2.3 <- lm(log(total_enrolled) ~ total_births +
                    median_household_income + 
                    contains_charter + 
                    pct_black
                  , data=df_full_compare)
summary(model.7.2.3)
plot(model.7.2.3)


model.7.2.4 <- lm(log(total_enrolled) ~ total_births +
                    median_household_income + 
                    contains_charter + 
                    pass_percent
                  , data=df_full_compare)
# not especially bad
summary(model.7.2.4)
plot(model.7.2.4)

vif(model.7.2.4)

# can't anova because the sets are different
anova(model.7.2.4, model.7.2.1)

#names(df_full_compare)

df_full_compare[c(242, 537),]

```


```{r, "Step"}

names(df_full_compare)

summary(df_full_compare$catchment_year)

df.step <- df_full_compare[c(1, 4, 5, 7, 13, 14, 17, 18, 19, 20, 21)]


step.model <- step(lm(log(total_enrolled) ~ . , data = df.step), direction = "both")

summary(step.model)

plot(step.model)

vif(step.model)




df.step.1 <- df_full_compare[c(1, 4, 7, 13, 14, 17, 18, 19, 20, 21)]
names(df.step.1)

df.step.1$log_total_enrolled <- log(df.step.1$total_enrolled)
df.step.1 <- df.step.1[ , -which(names(df.step.1) %in% c("total_enrolled"))]

names(df.step.1)

step.model.1 <- step(lm(log_total_enrolled ~ . , data = df.step.1), direction = "both")

summary(step.model.1)

#names(coefficients(step.model.1))[-1]

plot(step.model.1)

vif(step.model.1)


```



```{r, "evaluate_top_model"}
z.score=function(x){
  z=(x-mean(x))/sd(x)
  return(z)
}

# I tried to write good code. It didn't work. Don't blame me.
graph.model.z <- function(data, result){
  # print a graph of z scores using the z scores of data
  df.graph <- cbind(data)
  df.graph.z <- subset(df.graph, complete.cases(df.graph))
  
  df.graph.z <- data.frame(apply(df.graph.z, 2, FUN=z.score) )
  
  names(df.graph.z) <- names(df.graph)
  
  result_col <- df.graph.z[result]
  
  predictors <- df.graph.z[ , -which(names(df.graph.z) %in% c(result) )]
  
  model.graph <- lm(result_col, ~ predictors)
  
  #dwplot(model.graph)

}

#summary(df.step.1["total_enrolled"])

#graph.model.z(df.step.1, "total_enrolled")

# 1 make a dataframe of just the variables I want

names(df_full_compare)

summary(df_full_compare$pass_percent)

df.7.2.4 <- cbind(
  log(df_full_compare$total_enrolled),
  df_full_compare$total_births,
  df_full_compare$median_household_income,
  df_full_compare$contains_charter,
  df_full_compare$pass_percent
)

summary(df.7.2.4)

df.7.2.4.z <- subset(df.7.2.4, complete.cases(df.7.2.4))

summary(df.7.2.4.z)

df.7.2.4.z <- data.frame(apply(df.7.2.4.z, 2, FUN=z.score) )

summary(df.7.2.4.z)

names(df.7.2.4.z) <- c(
  "log_total_enrolled",
  "total_births",
  "median_household_income",
  "contains_charter",
  "pass_percent"
)


model.7.2.4.z <- lm(log_total_enrolled ~ total_births + median_household_income + contains_charter + pass_percent, data=df.7.2.4.z )

summary(model.7.2.4.z)


dwplot(model.7.2.4)
dwplot(model.7.2.4.z)



c.df.step.1 <- cbind(df.step.1)
c.df.step.1 <- subset(c.df.step.1, complete.cases(c.df.step.1))
c.df.step.1.z <- data.frame(apply(c.df.step.1, 2, FUN=z.score) )

names(c.df.step.1.z) <- names(df.step.1)

model.step.1.z <- lm(log_total_enrolled ~ . , data = c.df.step.1.z)
dwplot(model.step.1.z)

# need to remove the contains_charter because its coefficient might be zero. distance drives this one.

```

```{r, "remove_contains_charter}


df.step.2 <- df_full_compare[c(1, 4, 7, 13, 14, 18, 19, 20, 21)]

df.step.2$log_total_enrolled <- log(df.step.2$total_enrolled)
df.step.2 <- df.step.2[ , -which(names(df.step.2) %in% c("total_enrolled"))]

names(df.step.2)

model.step.2 <- lm(log_total_enrolled ~ . , data = df.step.2)

summary(model.step.2)
vif(model.step.2)

png("FinalReport.jpg")
plot(model.step.2)
dev.off()

df_full_compare[c(735, 205),]


c.df.step.2 <- cbind(df.step.2)
c.df.step.2 <- subset(c.df.step.2, complete.cases(c.df.step.2))
c.df.step.2.z <- data.frame(apply(c.df.step.2, 2, FUN=z.score) )

names(c.df.step.2.z) <- names(df.step.2)

model.step.2.z <- lm(log_total_enrolled ~ . , data = c.df.step.2.z)
coefficients(model.step.2.z)

png("FinalProject5.png")
dwplot(model.step.2.z)
dev.off()


```

```{r, "Teardown"}
dbDisconnect(connec)
```